[
    {
        "loss": 1.964,
        "grad_norm": 3.12174391746521,
        "learning_rate": 4.936251920122888e-05,
        "epoch": 0.12800819252432155,
        "step": 500
    },
    {
        "loss": 1.7329,
        "grad_norm": 3.3765358924865723,
        "learning_rate": 4.872247823860727e-05,
        "epoch": 0.2560163850486431,
        "step": 1000
    },
    {
        "loss": 1.731,
        "grad_norm": 4.632175922393799,
        "learning_rate": 4.808371735791091e-05,
        "epoch": 0.38402457757296465,
        "step": 1500
    },
    {
        "loss": 1.7693,
        "grad_norm": 3.1081297397613525,
        "learning_rate": 4.74436763952893e-05,
        "epoch": 0.5120327700972862,
        "step": 2000
    },
    {
        "loss": 1.6826,
        "grad_norm": 1.7782740592956543,
        "learning_rate": 4.680363543266769e-05,
        "epoch": 0.6400409626216078,
        "step": 2500
    },
    {
        "loss": 1.7027,
        "grad_norm": 1.7686882019042969,
        "learning_rate": 4.6163594470046084e-05,
        "epoch": 0.7680491551459293,
        "step": 3000
    },
    {
        "loss": 1.6579,
        "grad_norm": 8.598638534545898,
        "learning_rate": 4.5523553507424476e-05,
        "epoch": 0.8960573476702509,
        "step": 3500
    },
    {
        "loss": 1.6234,
        "grad_norm": 3.587522506713867,
        "learning_rate": 4.488351254480287e-05,
        "epoch": 1.0240655401945724,
        "step": 4000
    },
    {
        "loss": 1.6217,
        "grad_norm": 2.751554012298584,
        "learning_rate": 4.424347158218126e-05,
        "epoch": 1.1520737327188941,
        "step": 4500
    },
    {
        "loss": 1.6084,
        "grad_norm": 4.4422502517700195,
        "learning_rate": 4.360343061955965e-05,
        "epoch": 1.2800819252432156,
        "step": 5000
    },
    {
        "loss": 1.595,
        "grad_norm": 2.6668152809143066,
        "learning_rate": 4.2963389656938045e-05,
        "epoch": 1.4080901177675371,
        "step": 5500
    },
    {
        "loss": 1.59,
        "grad_norm": 8.379820823669434,
        "learning_rate": 4.232334869431644e-05,
        "epoch": 1.5360983102918588,
        "step": 6000
    },
    {
        "loss": 1.5955,
        "grad_norm": 7.10015344619751,
        "learning_rate": 4.1684587813620074e-05,
        "epoch": 1.66410650281618,
        "step": 6500
    },
    {
        "loss": 1.5308,
        "grad_norm": 4.479045391082764,
        "learning_rate": 4.1044546850998466e-05,
        "epoch": 1.7921146953405018,
        "step": 7000
    },
    {
        "loss": 1.4971,
        "grad_norm": 6.752324104309082,
        "learning_rate": 4.040450588837686e-05,
        "epoch": 1.9201228878648233,
        "step": 7500
    },
    {
        "loss": 1.5255,
        "grad_norm": 2.9181501865386963,
        "learning_rate": 3.976446492575525e-05,
        "epoch": 2.048131080389145,
        "step": 8000
    },
    {
        "loss": 1.5236,
        "grad_norm": 2.2777297496795654,
        "learning_rate": 3.912442396313364e-05,
        "epoch": 2.1761392729134665,
        "step": 8500
    },
    {
        "loss": 1.5108,
        "grad_norm": 4.440834999084473,
        "learning_rate": 3.8484383000512035e-05,
        "epoch": 2.3041474654377883,
        "step": 9000
    },
    {
        "loss": 1.4926,
        "grad_norm": 2.7909915447235107,
        "learning_rate": 3.784690220174091e-05,
        "epoch": 2.4321556579621095,
        "step": 9500
    },
    {
        "loss": 1.5447,
        "grad_norm": 9.184590339660645,
        "learning_rate": 3.72068612391193e-05,
        "epoch": 2.5601638504864312,
        "step": 10000
    },
    {
        "loss": 1.478,
        "grad_norm": 4.387234687805176,
        "learning_rate": 3.65668202764977e-05,
        "epoch": 2.688172043010753,
        "step": 10500
    },
    {
        "loss": 1.5011,
        "grad_norm": 10.248931884765625,
        "learning_rate": 3.5926779313876094e-05,
        "epoch": 2.8161802355350742,
        "step": 11000
    },
    {
        "loss": 1.448,
        "grad_norm": 2.0514562129974365,
        "learning_rate": 3.5286738351254486e-05,
        "epoch": 2.944188428059396,
        "step": 11500
    },
    {
        "loss": 1.46,
        "grad_norm": 6.339014053344727,
        "learning_rate": 3.464669738863288e-05,
        "epoch": 3.0721966205837172,
        "step": 12000
    },
    {
        "loss": 1.4608,
        "grad_norm": 7.504676342010498,
        "learning_rate": 3.400665642601127e-05,
        "epoch": 3.200204813108039,
        "step": 12500
    },
    {
        "loss": 1.4655,
        "grad_norm": 3.5388448238372803,
        "learning_rate": 3.336661546338966e-05,
        "epoch": 3.32821300563236,
        "step": 13000
    },
    {
        "loss": 1.4318,
        "grad_norm": 3.131237745285034,
        "learning_rate": 3.272785458269329e-05,
        "epoch": 3.456221198156682,
        "step": 13500
    },
    {
        "loss": 1.404,
        "grad_norm": 4.16353702545166,
        "learning_rate": 3.208909370199693e-05,
        "epoch": 3.5842293906810037,
        "step": 14000
    },
    {
        "loss": 1.4679,
        "grad_norm": 5.939687252044678,
        "learning_rate": 3.144905273937532e-05,
        "epoch": 3.712237583205325,
        "step": 14500
    },
    {
        "loss": 1.4433,
        "grad_norm": 4.750664234161377,
        "learning_rate": 3.0809011776753715e-05,
        "epoch": 3.8402457757296466,
        "step": 15000
    },
    {
        "loss": 1.4287,
        "grad_norm": 2.0621659755706787,
        "learning_rate": 3.0168970814132107e-05,
        "epoch": 3.9682539682539684,
        "step": 15500
    },
    {
        "loss": 1.4652,
        "grad_norm": 3.1704111099243164,
        "learning_rate": 2.95289298515105e-05,
        "epoch": 4.09626216077829,
        "step": 16000
    },
    {
        "loss": 1.4149,
        "grad_norm": 5.702635288238525,
        "learning_rate": 2.8888888888888888e-05,
        "epoch": 4.224270353302611,
        "step": 16500
    },
    {
        "loss": 1.4037,
        "grad_norm": 3.3385021686553955,
        "learning_rate": 2.824884792626728e-05,
        "epoch": 4.352278545826933,
        "step": 17000
    },
    {
        "loss": 1.3626,
        "grad_norm": 6.326888084411621,
        "learning_rate": 2.761008704557092e-05,
        "epoch": 4.480286738351254,
        "step": 17500
    },
    {
        "loss": 1.4159,
        "grad_norm": 5.192262649536133,
        "learning_rate": 2.6970046082949306e-05,
        "epoch": 4.6082949308755765,
        "step": 18000
    },
    {
        "loss": 1.4483,
        "grad_norm": 3.092099666595459,
        "learning_rate": 2.63300051203277e-05,
        "epoch": 4.736303123399898,
        "step": 18500
    },
    {
        "loss": 1.4334,
        "grad_norm": 4.8964691162109375,
        "learning_rate": 2.568996415770609e-05,
        "epoch": 4.864311315924219,
        "step": 19000
    },
    {
        "loss": 1.3837,
        "grad_norm": 2.806743621826172,
        "learning_rate": 2.5051203277009728e-05,
        "epoch": 4.99231950844854,
        "step": 19500
    },
    {
        "loss": 1.3824,
        "grad_norm": 10.990423202514648,
        "learning_rate": 2.4411162314388124e-05,
        "epoch": 5.1203277009728625,
        "step": 20000
    },
    {
        "loss": 1.3665,
        "grad_norm": 3.0947678089141846,
        "learning_rate": 2.3771121351766516e-05,
        "epoch": 5.248335893497184,
        "step": 20500
    },
    {
        "loss": 1.3848,
        "grad_norm": 7.325835704803467,
        "learning_rate": 2.3131080389144908e-05,
        "epoch": 5.376344086021505,
        "step": 21000
    },
    {
        "loss": 1.3975,
        "grad_norm": 8.700212478637695,
        "learning_rate": 2.24910394265233e-05,
        "epoch": 5.504352278545827,
        "step": 21500
    },
    {
        "loss": 1.378,
        "grad_norm": 4.010356426239014,
        "learning_rate": 2.185099846390169e-05,
        "epoch": 5.6323604710701485,
        "step": 22000
    },
    {
        "loss": 1.367,
        "grad_norm": 7.513988971710205,
        "learning_rate": 2.121095750128008e-05,
        "epoch": 5.76036866359447,
        "step": 22500
    },
    {
        "loss": 1.3576,
        "grad_norm": 4.6471381187438965,
        "learning_rate": 2.057219662058372e-05,
        "epoch": 5.888376856118792,
        "step": 23000
    },
    {
        "loss": 1.3712,
        "grad_norm": 7.861447811126709,
        "learning_rate": 1.993215565796211e-05,
        "epoch": 6.016385048643113,
        "step": 23500
    },
    {
        "loss": 1.3552,
        "grad_norm": 6.154510498046875,
        "learning_rate": 1.9292114695340503e-05,
        "epoch": 6.1443932411674345,
        "step": 24000
    },
    {
        "loss": 1.3502,
        "grad_norm": 4.454662322998047,
        "learning_rate": 1.8652073732718895e-05,
        "epoch": 6.272401433691757,
        "step": 24500
    },
    {
        "loss": 1.355,
        "grad_norm": 7.043622970581055,
        "learning_rate": 1.801331285202253e-05,
        "epoch": 6.400409626216078,
        "step": 25000
    },
    {
        "loss": 1.3468,
        "grad_norm": 5.059154987335205,
        "learning_rate": 1.737327188940092e-05,
        "epoch": 6.528417818740399,
        "step": 25500
    },
    {
        "loss": 1.3584,
        "grad_norm": 12.197810173034668,
        "learning_rate": 1.6733230926779313e-05,
        "epoch": 6.65642601126472,
        "step": 26000
    },
    {
        "loss": 1.3613,
        "grad_norm": 3.9760193824768066,
        "learning_rate": 1.6093189964157706e-05,
        "epoch": 6.784434203789043,
        "step": 26500
    },
    {
        "loss": 1.3497,
        "grad_norm": 2.869044542312622,
        "learning_rate": 1.5453149001536098e-05,
        "epoch": 6.912442396313364,
        "step": 27000
    },
    {
        "loss": 1.3495,
        "grad_norm": 15.580376625061035,
        "learning_rate": 1.4814388120839733e-05,
        "epoch": 7.040450588837686,
        "step": 27500
    },
    {
        "loss": 1.3176,
        "grad_norm": 4.617693901062012,
        "learning_rate": 1.4174347158218127e-05,
        "epoch": 7.168458781362007,
        "step": 28000
    },
    {
        "loss": 1.3412,
        "grad_norm": 4.001060962677002,
        "learning_rate": 1.353430619559652e-05,
        "epoch": 7.296466973886329,
        "step": 28500
    },
    {
        "loss": 1.3479,
        "grad_norm": 6.942239284515381,
        "learning_rate": 1.2894265232974912e-05,
        "epoch": 7.42447516641065,
        "step": 29000
    },
    {
        "loss": 1.3487,
        "grad_norm": 4.121782302856445,
        "learning_rate": 1.2254224270353302e-05,
        "epoch": 7.552483358934972,
        "step": 29500
    },
    {
        "loss": 1.3643,
        "grad_norm": 4.143219947814941,
        "learning_rate": 1.1614183307731694e-05,
        "epoch": 7.680491551459293,
        "step": 30000
    },
    {
        "loss": 1.3198,
        "grad_norm": 3.9026846885681152,
        "learning_rate": 1.0974142345110088e-05,
        "epoch": 7.808499743983615,
        "step": 30500
    },
    {
        "loss": 1.2892,
        "grad_norm": 9.509966850280762,
        "learning_rate": 1.0335381464413722e-05,
        "epoch": 7.936507936507937,
        "step": 31000
    },
    {
        "loss": 1.3673,
        "grad_norm": 2.903964042663574,
        "learning_rate": 9.695340501792114e-06,
        "epoch": 8.064516129032258,
        "step": 31500
    },
    {
        "loss": 1.3111,
        "grad_norm": 11.67066764831543,
        "learning_rate": 9.055299539170507e-06,
        "epoch": 8.19252432155658,
        "step": 32000
    },
    {
        "loss": 1.3659,
        "grad_norm": 8.069602012634277,
        "learning_rate": 8.4152585765489e-06,
        "epoch": 8.3205325140809,
        "step": 32500
    },
    {
        "loss": 1.2713,
        "grad_norm": 5.875398635864258,
        "learning_rate": 7.775217613927293e-06,
        "epoch": 8.448540706605222,
        "step": 33000
    },
    {
        "loss": 1.3478,
        "grad_norm": 3.7769482135772705,
        "learning_rate": 7.136456733230927e-06,
        "epoch": 8.576548899129545,
        "step": 33500
    },
    {
        "loss": 1.3047,
        "grad_norm": 3.0720221996307373,
        "learning_rate": 6.4964157706093195e-06,
        "epoch": 8.704557091653866,
        "step": 34000
    },
    {
        "loss": 1.3225,
        "grad_norm": 10.471675872802734,
        "learning_rate": 5.856374807987712e-06,
        "epoch": 8.832565284178187,
        "step": 34500
    },
    {
        "loss": 1.3018,
        "grad_norm": 9.490659713745117,
        "learning_rate": 5.216333845366104e-06,
        "epoch": 8.960573476702509,
        "step": 35000
    },
    {
        "loss": 1.3171,
        "grad_norm": 3.6835718154907227,
        "learning_rate": 4.577572964669739e-06,
        "epoch": 9.08858166922683,
        "step": 35500
    },
    {
        "loss": 1.3228,
        "grad_norm": 5.009510517120361,
        "learning_rate": 3.937532002048131e-06,
        "epoch": 9.216589861751151,
        "step": 36000
    },
    {
        "loss": 1.3023,
        "grad_norm": 2.638444662094116,
        "learning_rate": 3.2974910394265234e-06,
        "epoch": 9.344598054275474,
        "step": 36500
    },
    {
        "loss": 1.2848,
        "grad_norm": 11.018571853637695,
        "learning_rate": 2.6574500768049156e-06,
        "epoch": 9.472606246799796,
        "step": 37000
    },
    {
        "loss": 1.3147,
        "grad_norm": 9.507741928100586,
        "learning_rate": 2.017409114183308e-06,
        "epoch": 9.600614439324117,
        "step": 37500
    },
    {
        "loss": 1.3056,
        "grad_norm": 4.325129985809326,
        "learning_rate": 1.3786482334869433e-06,
        "epoch": 9.728622631848438,
        "step": 38000
    },
    {
        "loss": 1.316,
        "grad_norm": 3.9033706188201904,
        "learning_rate": 7.386072708653353e-07,
        "epoch": 9.85663082437276,
        "step": 38500
    },
    {
        "loss": 1.371,
        "grad_norm": 3.2345354557037354,
        "learning_rate": 9.856630824372762e-08,
        "epoch": 9.98463901689708,
        "step": 39000
    },
    {
        "train_runtime": 3414.5774,
        "train_samples_per_second": 22.875,
        "train_steps_per_second": 11.439,
        "total_flos": 2.2898070968303616e+16,
        "train_loss": 1.4369741710344461,
        "epoch": 10.0,
        "step": 39060
    }
]